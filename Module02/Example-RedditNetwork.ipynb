{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Using PRAW to Create Networks\n",
    "\n",
    "This notebook contains examples for using web-based APIs (Application Programmer Interfaces) to download data from social media platforms.\n",
    "\n",
    "This notebook focuses specifically on _Reddit_.\n",
    "\n",
    "We will use this API to create a network from the Reddit data, focusing on who replied to whom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Import `NetworkX` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to make sure we have networkx installed...\n",
    "!pip install networkx\n",
    "\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Reddit API\n",
    "\n",
    "Reddit's API used to be the easiest to use since it did not require credentials to access data on its subreddit pages.\n",
    "Unfortunately, this process has been changed, and developers now need to create a Reddit application on Reddit's app page located here: (https://www.reddit.com/prefs/apps/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to make sure we have praw installed...\n",
    "!pip install praw\n",
    "\n",
    "# For our first piece of code, we need to import the package \n",
    "# that connects to Reddit. Praw is a thin wrapper around reddit's \n",
    "# web APIs and works well\n",
    "\n",
    "import praw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Reddit Application\n",
    "Go to https://www.reddit.com/prefs/apps/.\n",
    "Scroll down to \"create application\", select \"web app\", and provide a name, description, and URL (which can be anything).\n",
    "\n",
    "After you press \"create app\", you will be redirected to a new page with information about your application. Copy the unique identifiers below \"web app\" and beside \"secret\". These are your client_id and client_secret values, which you need below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we specify a \"unique\" user agent for our code\n",
    "# This is primarily for identification, I think, and some\n",
    "# user-agents of bad actors might be blocked\n",
    "redditApi = praw.Reddit(client_id='xxx',\n",
    "                        client_secret='xxx',\n",
    "                        user_agent='is688_cbuntain_v01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Reddit Comments\n",
    "\n",
    "While you're never supposed to read the comments, for certain live streams or new and rising posts, the comments may provide useful insight into events on the ground or people's sentiment.\n",
    "New posts may not have comments yet though.\n",
    "\n",
    "Comments are attached to the post title, so for a given submission, you can pull its comments directly.\n",
    "\n",
    "Note Reddit returns pages of comments to prevent server overload, so you will not get all comments at once and will have to write code for getting more comments than the top ones returned at first.\n",
    "This pagination is performed using the MoreXYZ objects (e.g., MoreComments or MorePosts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_node_adder(g, comment, parent_author):\n",
    "    '''Recursively process comments and add them to the graph'''\n",
    "    \n",
    "    # Check if we have the node already in our graph\n",
    "    if comment.author not in g.nodes:\n",
    "        g.add_node(comment.author)\n",
    "        \n",
    "    # Create an edge between this comment author and the\n",
    "    #  parent author\n",
    "    g.add_edge(comment.author, parent_author)\n",
    "\n",
    "    # Iterate through the comments\n",
    "    for reply in comment.replies.list():\n",
    "        if isinstance(reply, praw.models.MoreComments):\n",
    "            continue\n",
    "            \n",
    "        # Recursively process this reply\n",
    "        recursive_node_adder(g, reply, comment.author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Populate the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create an undirected graph\n",
    "g = nx.Graph()\n",
    "\n",
    "\n",
    "subreddit = \"worldnews\"\n",
    "\n",
    "breadthCommentCount = 10\n",
    "\n",
    "targetSub = redditApi.subreddit(subreddit)\n",
    "\n",
    "submissions = targetSub.hot(limit=20)\n",
    "\n",
    "for post in submissions:\n",
    "    print (post.author, \"-\", post.title)\n",
    "    \n",
    "    # Check if we have the node already in our graph\n",
    "    if post.author not in g.nodes:\n",
    "        g.add_node(post.author)\n",
    "    \n",
    "    post.comment_limit = breadthCommentCount\n",
    "    \n",
    "    # Get the top few comments\n",
    "    for comment in post.comments.list():\n",
    "        \n",
    "        # Skip MoreComment objects, which don't have authors\n",
    "        if isinstance(comment, praw.models.MoreComments):\n",
    "            continue\n",
    "        \n",
    "        # Recursively process this reply\n",
    "        recursive_node_adder(g, comment, post.author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Graph\n",
    "\n",
    "We export the graph using GraphML in `NetworkX`, so we can load it in other software later.\n",
    "\n",
    "Note, we could use other formats here as well. GraphML is just convenient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_graphml(g, \"output.reddit.graphml\", prettyprint=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw the Graph\n",
    "\n",
    "Now that we've made the graph, let's draw it using the layout algorithms in `NetworkX`.\n",
    "\n",
    "_NOTE_: `NetworkX` is not meant for graph layouts. We only do this for illustrative purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Spring layout algorithm\n",
    "pos = nx.spring_layout(g, scale=200, iterations=100, k=0.2)\n",
    "\n",
    "# And draw the graph with node labels\n",
    "nx.draw(g, \n",
    "        pos, \n",
    "        node_color='#A0CBE2', \n",
    "        width=1, \n",
    "        with_labels=True,\n",
    "        node_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
